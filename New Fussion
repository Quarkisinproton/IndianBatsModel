{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aef54b6c",
   "metadata": {
    "papermill": {
     "duration": 0.002184,
     "end_time": "2025-12-20T09:34:28.285776",
     "exception": false,
     "start_time": "2025-12-20T09:34:28.283592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Kaggle Training Pipeline for IndianBatsModel\n",
    "\n",
    "This notebook trains the Bat Species Classifier using code from the [IndianBatsModel repository](https://github.com/Quarkisinproton/IndianBatsModel).\n",
    "\n",
    "**Steps:**\n",
    "1.  Clone the repository.\n",
    "2.  Install dependencies.\n",
    "3.  Import functions directly from the codebase.\n",
    "4.  Run the data preparation and training pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80b3200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T09:34:28.290597Z",
     "iopub.status.busy": "2025-12-20T09:34:28.290007Z",
     "iopub.status.idle": "2025-12-20T09:34:33.539542Z",
     "shell.execute_reply": "2025-12-20T09:34:33.538802Z"
    },
    "papermill": {
     "duration": 5.25356,
     "end_time": "2025-12-20T09:34:33.541307",
     "exception": false,
     "start_time": "2025-12-20T09:34:28.287747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'IndianBatsModel'...\r\n",
      "remote: Enumerating objects: 273, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (30/30), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (24/24), done.\u001b[K\r\n",
      "remote: Total 273 (delta 11), reused 20 (delta 6), pack-reused 243 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (273/273), 125.92 KiB | 2.52 MiB/s, done.\r\n",
      "Resolving deltas: 100% (147/147), done.\r\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.3)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\r\n",
      "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\r\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.2)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\r\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\r\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\r\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.15.0)\r\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.3->librosa) (2.4.1)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.5.0)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.5)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.10.5)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.3->librosa) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.3->librosa) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.3->librosa) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.3->librosa) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.3->librosa) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.3->librosa) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup Environment\n",
    "# Clone the repository\n",
    "!git clone https://github.com/Quarkisinproton/IndianBatsModel.git\n",
    "\n",
    "# Install dependencies\n",
    "!pip install librosa pyyaml pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84744a98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T09:34:33.547261Z",
     "iopub.status.busy": "2025-12-20T09:34:33.546826Z",
     "iopub.status.idle": "2025-12-20T09:34:44.077852Z",
     "shell.execute_reply": "2025-12-20T09:34:44.076995Z"
    },
    "papermill": {
     "duration": 10.535389,
     "end_time": "2025-12-20T09:34:44.079131",
     "exception": false,
     "start_time": "2025-12-20T09:34:33.543742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "# 2. Import Modules\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add paths to sys.path to allow importing modules\n",
    "REPO_DIR = '/kaggle/working/IndianBatsModel'\n",
    "SRC_DIR = os.path.join(REPO_DIR, 'src')\n",
    "\n",
    "# Add both repo root (for 'src.data_prep' imports) and src (for 'datasets' imports)\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.append(REPO_DIR)\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.append(SRC_DIR)\n",
    "\n",
    "# Import project modules directly\n",
    "try:\n",
    "    from src.data_prep.generate_annotations import generate_annotations\n",
    "    from src.data_prep.wombat_to_spectrograms import process_all as generate_spectrograms\n",
    "    from src.data_prep.extract_end_frequency import process_all_and_write_csv as extract_features\n",
    "    from src.data_prep.whombat_project_to_wombat import convert_whombat_project_to_wombat_jsons\n",
    "    from src.train import train_model\n",
    "    print(\"Imports successful!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import Error: {e}\")\n",
    "    # Fallback: Try importing without 'src.' prefix if path setup behaves differently\n",
    "    from data_prep.generate_annotations import generate_annotations\n",
    "    from data_prep.wombat_to_spectrograms import process_all as generate_spectrograms\n",
    "    from data_prep.extract_end_frequency import process_all_and_write_csv as extract_features\n",
    "    from data_prep.whombat_project_to_wombat import convert_whombat_project_to_wombat_jsons\n",
    "    from train import train_model\n",
    "    print(\"Imports successful (fallback)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55cda4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T09:34:44.085121Z",
     "iopub.status.busy": "2025-12-20T09:34:44.084454Z",
     "iopub.status.idle": "2025-12-20T09:34:44.091010Z",
     "shell.execute_reply": "2025-12-20T09:34:44.090300Z"
    },
    "papermill": {
     "duration": 0.010527,
     "end_time": "2025-12-20T09:34:44.092047",
     "exception": false,
     "start_time": "2025-12-20T09:34:44.081520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set.\n"
     ]
    }
   ],
   "source": [
    "# 3. Configuration\n",
    "WORK_DIR = '/kaggle/working'\n",
    "\n",
    "# Input Data Paths (Adjust these to match your Kaggle Dataset structure)\n",
    "RAW_AUDIO_DIRS = [\n",
    "    '/kaggle/input/pip-ceylonicusbat-species',\n",
    "    '/kaggle/input/pip-tenuisbat-species',\n",
    "]\n",
    "\n",
    "# Annotation mode\n",
    "# - 'auto': generate dummy full-file annotations from folder names (NOT RECOMMENDED for call classification)\n",
    "# - 'provided': convert Whombat project JSON exports into per-audio Wombat JSONs (RECOMMENDED)\n",
    "ANNOTATION_MODE = 'provided'  # 'auto' or 'provided'\n",
    "\n",
    "# Only used when ANNOTATION_MODE == 'provided'\n",
    "# Put the Whombat project export JSON paths here (e.g. exported from Whombat)\n",
    "WHOMBAT_PROJECT_JSONS = [\n",
    "    '/kaggle/input/annotations-tenuis-ceylonicus/tenuis annotations.json',\n",
    "    '/kaggle/input/annotations-tenuis-ceylonicus/Pip ceylonicus.json',\n",
    "]\n",
    "\n",
    "# Output Paths\n",
    "JSON_DIR = os.path.join(WORK_DIR, 'data/annotations_json_folder')\n",
    "SPECT_OUT = os.path.join(WORK_DIR, 'data/processed/spectrograms')\n",
    "FEATURES_OUT = os.path.join(WORK_DIR, 'data/processed/features')\n",
    "FEATURES_CSV = os.path.join(FEATURES_OUT, 'end_frequencies.csv')\n",
    "MODEL_SAVE_PATH = os.path.join(WORK_DIR, 'models', 'bat_fused_best.pth')\n",
    "\n",
    "# Ensure directories exist\n",
    "Path(JSON_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(FEATURES_OUT).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.path.dirname(MODEL_SAVE_PATH)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Configuration set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "039021e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T09:34:44.097333Z",
     "iopub.status.busy": "2025-12-20T09:34:44.097154Z",
     "iopub.status.idle": "2025-12-20T09:34:44.119093Z",
     "shell.execute_reply": "2025-12-20T09:34:44.118474Z"
    },
    "papermill": {
     "duration": 0.025854,
     "end_time": "2025-12-20T09:34:44.120174",
     "exception": false,
     "start_time": "2025-12-20T09:34:44.094320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Annotations...\n",
      "Mode: provided (convert Whombat project JSON exports)\n",
      "Converted /kaggle/input/annotations-tenuis-ceylonicus/tenuis annotations.json: jsons_written=3, sound_events_written=71, skipped_unlabeled=1\n",
      "Converted /kaggle/input/annotations-tenuis-ceylonicus/Pip ceylonicus.json: jsons_written=18, sound_events_written=127, skipped_unlabeled=1\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# 4. Generate/Convert Annotations\n",
    "print(\"Preparing Annotations...\")\n",
    "\n",
    "if ANNOTATION_MODE == 'auto':\n",
    "    print(\"Mode: auto (generate dummy full-file annotations)\")\n",
    "    generate_annotations(\n",
    "        raw_audio_dirs=RAW_AUDIO_DIRS,\n",
    "        output_dir=JSON_DIR,\n",
    "        label_strategy='folder',\n",
    "    )\n",
    "elif ANNOTATION_MODE == 'provided':\n",
    "    print(\"Mode: provided (convert Whombat project JSON exports)\")\n",
    "    if not WHOMBAT_PROJECT_JSONS:\n",
    "        raise ValueError(\"WHOMBAT_PROJECT_JSONS is empty. Add your Whombat project export JSON paths.\")\n",
    "    for pj in WHOMBAT_PROJECT_JSONS:\n",
    "        summary = convert_whombat_project_to_wombat_jsons(\n",
    "            project_json_path=pj,\n",
    "            output_dir=JSON_DIR,\n",
    "            tag_key='Species',\n",
    "            skip_unlabeled=True,\n",
    "        )\n",
    "        print(f\"Converted {pj}: jsons_written={summary.jsons_written}, sound_events_written={summary.sound_events_written}, skipped_unlabeled={summary.sound_events_skipped_unlabeled}\")\n",
    "else:\n",
    "    raise ValueError(f\"Unknown ANNOTATION_MODE: {ANNOTATION_MODE}\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f6fe831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T09:34:44.125615Z",
     "iopub.status.busy": "2025-12-20T09:34:44.125213Z",
     "iopub.status.idle": "2025-12-20T09:35:08.085296Z",
     "shell.execute_reply": "2025-12-20T09:35:08.084518Z"
    },
    "papermill": {
     "duration": 23.964291,
     "end_time": "2025-12-20T09:35:08.086674",
     "exception": false,
     "start_time": "2025-12-20T09:34:44.122383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Spectrograms...\n",
      "Scanning for JSONs in /kaggle/working/data/annotations_json_folder...\n",
      "Found 21 JSON files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:   0%|          | 0/21 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py:2148: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "Processing JSONs:  14%|█▍        | 3/21 [00:15<01:04,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not find audio for pt2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  38%|███▊      | 8/21 [00:16<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not find audio for pt1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  71%|███████▏  | 15/21 [00:19<00:02,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not find audio for pt3.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs: 100%|██████████| 21/21 [00:23<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 18 files successfully.\n",
      "Checking output directory: /kaggle/working/data/processed/spectrograms\n",
      "Found 2 species folders: ['Pip._tenuis', 'Sco._heathii__Pip._ceylonicus']\n",
      "Total spectrogram images found: 127\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Generate Spectrograms\n",
    "print(\"Generating Spectrograms...\")\n",
    "generate_spectrograms(\n",
    "    raw_audio_dirs=RAW_AUDIO_DIRS,\n",
    "    json_dir=JSON_DIR,\n",
    "    out_dir=SPECT_OUT,\n",
    "    species_key='label'\n",
    ")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75b8a767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T09:35:08.095371Z",
     "iopub.status.busy": "2025-12-20T09:35:08.094962Z",
     "iopub.status.idle": "2025-12-20T09:35:08.472298Z",
     "shell.execute_reply": "2025-12-20T09:35:08.471537Z"
    },
    "papermill": {
     "duration": 0.382974,
     "end_time": "2025-12-20T09:35:08.473524",
     "exception": false,
     "start_time": "2025-12-20T09:35:08.090550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Features...\n",
      "Features saved to /kaggle/working/data/processed/features/end_frequencies.csv\n"
     ]
    }
   ],
   "source": [
    "# 6. Extract Features\n",
    "print(\"Extracting Features...\")\n",
    "extract_features(\n",
    "    raw_audio_dirs=RAW_AUDIO_DIRS,\n",
    "    json_dir=JSON_DIR,\n",
    "    out_csv=FEATURES_CSV,\n",
    "    species_key='label'\n",
    ")\n",
    "print(f\"Features saved to {FEATURES_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a59f0b52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T09:35:08.481616Z",
     "iopub.status.busy": "2025-12-20T09:35:08.481378Z",
     "iopub.status.idle": "2025-12-20T09:35:29.928689Z",
     "shell.execute_reply": "2025-12-20T09:35:29.927754Z"
    },
    "papermill": {
     "duration": 21.452671,
     "end_time": "2025-12-20T09:35:29.929970",
     "exception": false,
     "start_time": "2025-12-20T09:35:08.477299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected num_classes=2 from /kaggle/working/data/processed/spectrograms\n",
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 162MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 507.0092\n",
      "Epoch [2/20], Loss: 215.9872\n",
      "Epoch [3/20], Loss: 280.2634\n",
      "Epoch [4/20], Loss: 238.4267\n",
      "Epoch [5/20], Loss: 281.7380\n",
      "Epoch [6/20], Loss: 210.6865\n",
      "Epoch [7/20], Loss: 266.1240\n",
      "Epoch [8/20], Loss: 211.2761\n",
      "Epoch [9/20], Loss: 119.4062\n",
      "Epoch [10/20], Loss: 138.6039\n",
      "Epoch [11/20], Loss: 185.9993\n",
      "Epoch [12/20], Loss: 155.7960\n",
      "Epoch [13/20], Loss: 201.3232\n",
      "Epoch [14/20], Loss: 148.4936\n",
      "Epoch [15/20], Loss: 150.0006\n",
      "Epoch [16/20], Loss: 117.3708\n",
      "Epoch [17/20], Loss: 128.2034\n",
      "Epoch [18/20], Loss: 123.6548\n",
      "Epoch [19/20], Loss: 169.2697\n",
      "Epoch [20/20], Loss: 83.7774\n",
      "Saved model to /kaggle/working/models/bat_fused_best.pth\n",
      "Training Complete! Model saved to /kaggle/working/models/bat_fused_best.pth\n"
     ]
    }
   ],
   "source": [
    "# 7. Run Training\n",
    "# Infer num_classes from generated spectrogram folders\n",
    "num_classes = len([p for p in Path(SPECT_OUT).iterdir() if p.is_dir()])\n",
    "print(f\"Detected num_classes={num_classes} from {SPECT_OUT}\")\n",
    "\n",
    "# Define Training Configuration Dictionary\n",
    "config = {\n",
    "    'data': {\n",
    "        'train_spectrograms': SPECT_OUT,\n",
    "        'features_csv': FEATURES_CSV,\n",
    "        'num_classes': num_classes,\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 9,\n",
    "        'learning_rate': 1e-4,\n",
    "        'num_epochs': 20,\n",
    "        'model_save_path': MODEL_SAVE_PATH,\n",
    "        'num_workers': 8,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Starting Training...\")\n",
    "train_model(config)\n",
    "print(f\"Training Complete! Model saved to {MODEL_SAVE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8811467,
     "sourceId": 13835459,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8811486,
     "sourceId": 13835480,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9080903,
     "sourceId": 14233920,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 68.066004,
   "end_time": "2025-12-20T09:35:32.565460",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-20T09:34:24.499456",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
