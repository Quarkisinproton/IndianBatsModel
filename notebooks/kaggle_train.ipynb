{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0530d70b",
   "metadata": {},
   "source": [
    "# Kaggle Training Pipeline for IndianBatsModel\n",
    "\n",
    "This notebook is designed to be imported into Kaggle to train the Bat Species Classifier.\n",
    "It handles:\n",
    "1.  Cloning the private repository (using a GitHub Token).\n",
    "2.  Installing dependencies.\n",
    "3.  **Generating Annotations**: Scans raw audio files and creates labels based on folder names.\n",
    "4.  Preparing the data (Spectrogram generation + Feature extraction).\n",
    "5.  Configuring and running the training loop.\n",
    "6.  Saving the best model.\n",
    "\n",
    "**Prerequisites:**\n",
    "*   You need a GitHub Personal Access Token (Classic) with `repo` scope.\n",
    "*   Upload your audio data to Kaggle Datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d21586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Notebook Version: 1.2 (Robust Pathing)\")\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# PASTE YOUR GITHUB TOKEN HERE\n",
    "# (Format: \"ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "GITHUB_TOKEN = \"YOUR_TOKEN_HERE\" \n",
    "\n",
    "# Define Paths\n",
    "WORK_DIR = '/kaggle/working'\n",
    "REPO_NAME = 'IndianBatsModel'\n",
    "REPO_URL = f'https://{GITHUB_TOKEN}@github.com/Quarkisinproton/IndianBatsModel.git'\n",
    "REPO_DIR = os.path.join(WORK_DIR, REPO_NAME)\n",
    "\n",
    "# Input Data Paths (Adjust these to match your Kaggle Dataset structure)\n",
    "RAW_AUDIO_DIRS = [\n",
    "    '/kaggle/input/pip-ceylonicusbat-species',\n",
    "    '/kaggle/input/pip-tenuisbat-species'\n",
    "]\n",
    "\n",
    "# Output Paths\n",
    "# JSON_DIR: Where the GENERATED annotations will be saved.\n",
    "JSON_DIR = '/kaggle/working/data/annotations_json_folder' \n",
    "\n",
    "SPECT_OUT = os.path.join(WORK_DIR, 'data/processed/spectrograms')\n",
    "FEATURES_OUT = os.path.join(WORK_DIR, 'data/processed/features')\n",
    "FEATURES_CSV = os.path.join(FEATURES_OUT, 'end_frequencies.csv')\n",
    "MODEL_SAVE_PATH = os.path.join(WORK_DIR, 'models', 'bat_fused_best.pth')\n",
    "\n",
    "print(\"Configuration set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf526fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clone Repository\n",
    "if os.path.exists(REPO_DIR):\n",
    "    print(f\"Removing existing repo at {REPO_DIR}...\")\n",
    "    shutil.rmtree(REPO_DIR)\n",
    "\n",
    "print(\"Cloning repository...\")\n",
    "safe_url = REPO_URL.replace(GITHUB_TOKEN, \"********\") if \"ghp\" in GITHUB_TOKEN else REPO_URL\n",
    "print(f\"Cloning from: {safe_url}\")\n",
    "\n",
    "try:\n",
    "    # FORCE BRANCH 'main' to ensure we get the latest code\n",
    "    subprocess.run(['git', 'clone', '-b', 'main', REPO_URL, REPO_NAME], cwd=WORK_DIR, check=True)\n",
    "    print(\"Clone successful.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error cloning repo: {e}\")\n",
    "    # Fallback if token is missing/invalid, maybe the user uploaded the code manually?\n",
    "    if not os.path.exists(REPO_DIR):\n",
    "        print(\"CRITICAL: Repository not found. Please check your token or upload code manually.\")\n",
    "\n",
    "# Setup Environment\n",
    "# Robustly find the 'src' directory (in case of nested folders like IndianBatsModel/IndianBatsModel)\n",
    "PROJECT_ROOT = REPO_DIR\n",
    "found_src = False\n",
    "for root, dirs, files in os.walk(REPO_DIR):\n",
    "    if 'src' in dirs:\n",
    "        PROJECT_ROOT = root\n",
    "        found_src = True\n",
    "        print(f\"Found 'src' directory at: {os.path.join(root, 'src')}\")\n",
    "        print(f\"Setting PROJECT_ROOT to: {PROJECT_ROOT}\")\n",
    "        break\n",
    "\n",
    "if not found_src:\n",
    "    print(\"WARNING: 'src' directory not found in repository. Listing files for debug:\")\n",
    "    subprocess.run(['find', REPO_DIR, '-maxdepth', '3', '-not', '-path', '*/.*'], check=False)\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# Debug: Print Commit Info\n",
    "print(\"Current Commit:\")\n",
    "subprocess.run(['git', 'log', '-1'], check=False)\n",
    "\n",
    "# Prepare env for subprocesses\n",
    "env = os.environ.copy()\n",
    "env['PYTHONPATH'] = PROJECT_ROOT + os.pathsep + env.get('PYTHONPATH', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ddf066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Install Dependencies\n",
    "print(\"Installing dependencies...\")\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'install', 'librosa', 'pyyaml', 'pandas', 'matplotlib'], check=True)\n",
    "print(\"Dependencies installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Generate Annotations (Since we don't have JSONs for all files)\n",
    "# This step creates \"dummy\" annotations assuming each file contains one call of the species.\n",
    "# We use 'folder' strategy: The folder name (e.g., 'pip-ceylonicusbat-species') becomes the label.\n",
    "# If you want the filename to be the label, change label_strategy to 'filename'.\n",
    "\n",
    "print(\"Generating Annotations...\")\n",
    "Path(JSON_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Use PROJECT_ROOT found in step 1\n",
    "gen_script = os.path.join(PROJECT_ROOT, 'src', 'data_prep', 'generate_annotations.py')\n",
    "print(f\"Looking for script at: {gen_script}\")\n",
    "\n",
    "if not os.path.exists(gen_script):\n",
    "    print(f\"ERROR: Script not found at {gen_script}\")\n",
    "    # Fallback search for the file specifically\n",
    "    print(\"Searching for generate_annotations.py...\")\n",
    "    try:\n",
    "        # Find all matches, decode, strip whitespace, and split by newline\n",
    "        found_scripts = subprocess.check_output(['find', REPO_DIR, '-name', 'generate_annotations.py']).decode().strip().split('\\n')\n",
    "        # Filter out empty strings\n",
    "        found_scripts = [s for s in found_scripts if s]\n",
    "        \n",
    "        if found_scripts:\n",
    "            # Take the first match\n",
    "            found_script = found_scripts[0]\n",
    "            print(f\"Found script at: {found_script}\")\n",
    "            gen_script = found_script\n",
    "        else:\n",
    "            print(\"CRITICAL: generate_annotations.py not found anywhere!\")\n",
    "            subprocess.run(['find', REPO_DIR, '-maxdepth', '3', '-not', '-path', '*/.*'], check=False)\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"Error running find command.\")\n",
    "\n",
    "cmd_gen_ann = [\n",
    "    sys.executable, gen_script, # Run by path to avoid module issues\n",
    "    '--raw_audio_dirs', *RAW_AUDIO_DIRS,\n",
    "    '--output_dir', JSON_DIR,\n",
    "    '--label_strategy', 'folder' # Change to 'filename' if you prefer\n",
    "]\n",
    "subprocess.run(cmd_gen_ann, check=True, env=env)\n",
    "print(\"Annotation generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44244c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Preparation: Spectrograms\n",
    "# Ensure output directories exist\n",
    "Path(SPECT_OUT).mkdir(parents=True, exist_ok=True)\n",
    "Path(FEATURES_OUT).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Generating Spectrograms...\")\n",
    "cmd_spect = [\n",
    "    sys.executable, '-m', 'src.data_prep.wombat_to_spectrograms',\n",
    "    '--raw_audio_dir', *RAW_AUDIO_DIRS,\n",
    "    '--json_dir', JSON_DIR,\n",
    "    '--out_dir', SPECT_OUT,\n",
    "    '--species_key', 'label'\n",
    "]\n",
    "subprocess.run(cmd_spect, check=True, env=env)\n",
    "print(\"Spectrogram generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e2630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Data Preparation: Features\n",
    "print(\"Extracting Features...\")\n",
    "cmd_feat = [\n",
    "    sys.executable, '-m', 'src.data_prep.extract_end_frequency',\n",
    "    '--raw_audio_dir', *RAW_AUDIO_DIRS,\n",
    "    '--json_dir', JSON_DIR,\n",
    "    '--out_csv', FEATURES_CSV,\n",
    "    '--species_key', 'label'\n",
    "]\n",
    "subprocess.run(cmd_feat, check=True, env=env)\n",
    "print(f\"Features extracted to {FEATURES_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de48539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create Configuration\n",
    "cfg_dir = Path('configs')\n",
    "cfg_dir.mkdir(exist_ok=True)\n",
    "cfg_path = cfg_dir / 'config.yaml'\n",
    "\n",
    "cfg_content = f\"\"\"\n",
    "data:\n",
    "  train_spectrograms: \"{SPECT_OUT}\"\n",
    "  features_csv: \"{FEATURES_CSV}\"\n",
    "  num_classes: 3\n",
    "\n",
    "training:\n",
    "  batch_size: 8\n",
    "  learning_rate: 1e-4\n",
    "  num_epochs: 10\n",
    "  model_save_path: \"{MODEL_SAVE_PATH}\"\n",
    "  num_workers: 2\n",
    "\"\"\"\n",
    "cfg_path.write_text(cfg_content.strip())\n",
    "print(f'Wrote config to {cfg_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Run Training\n",
    "print(\"Starting Training...\")\n",
    "cmd_train = [sys.executable, 'src/train.py']\n",
    "subprocess.run(cmd_train, check=True, env=env)\n",
    "print(\"Training Complete!\")\n",
    "\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    print(f\"Model saved successfully at: {MODEL_SAVE_PATH}\")\n",
    "else:\n",
    "    print(\"Warning: Model file not found after training.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
